{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='font-family: CMU Sans Serif, sans-serif;'> Addressing missing data  </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook looks at the amount of missing data and tries to handle it correctly. The data was sourced from Wharton Research Data Services (WRDS) and produces by the Global Factor Data (GFD) team. Below we import the necessary packages for cleaning data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import janitor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally some notebook setup is done below. Specifically we adjust the notebook width for better presentation of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.width', 0)  # Use full cell width\n",
    "pd.set_option('display.expand_frame_repr', False)  # Prevent line breaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='font-family: CMU Sans Serif, sans-serif;'> Loading data and supporting information  </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data was downloaded in `../data__collect.ipynb` and is here imported for cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path to where the data is located\n",
    "dataPath = \"../data__collect/usa__gfd.parquet\"\n",
    "\n",
    "# Read data to raw data\n",
    "dataRawGfdUs = pd.read_parquet(dataPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides importing data we also want information about the features provided by the GFD team. We import the label clusters and features details, which can also be used to determine basis and primary features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw URL to label clusters and details from GFD repo\n",
    "urlLabelClustersGfd = \"https://raw.githubusercontent.com/bkelly-lab/ReplicationCrisis/master/GlobalFactors/Cluster%20Labels.csv\"\n",
    "urlLabelDetailsGfd = \"https://raw.githubusercontent.com/bkelly-lab/ReplicationCrisis/master/GlobalFactors/Factor%20Details.xlsx\"\n",
    "\n",
    "# Read dataframes\n",
    "dataLabelClustersGfd = pd.read_csv(urlLabelClustersGfd)\n",
    "dataLabelDetailsGfd = pd.read_excel(urlLabelDetailsGfd)\n",
    "\n",
    "# Create list of primary characters\n",
    "listPrimaryFeatures = dataLabelClustersGfd['characteristic'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='font-family: CMU Sans Serif, sans-serif;'> EDA  </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='font-family: CMU Sans Serif, sans-serif;'> Feature category check  </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before removing/imputation, transformation, feature engineering etc. we need to understand our data; how it is structured, what each variable tells us and its type, etc. To keep track of this we create a data dictionary. We are focused on the primary features (153) which are used to describe each firm, and the basis features (39) are generally less erroneous. \n",
    "\n",
    "We have 153 primary features and the rest are basis features. First we confirm that we have the 153 primary features and then how many basis features we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count basis features: 39\n",
      "Count primary features: 153\n",
      "Count of total observed features: 192\n"
     ]
    }
   ],
   "source": [
    "# Create list of observed primary features and basis features\n",
    "listObsPrimaryFeatures = [feature for feature in dataRawGfdUs.columns.tolist() if feature in listPrimaryFeatures]\n",
    "listObsBasisFeatures = [feature for feature in dataRawGfdUs.columns.tolist() if feature not in listPrimaryFeatures]\n",
    "\n",
    "# Count len of observed feature types\n",
    "intCountBasisFeatures = len(listObsBasisFeatures)\n",
    "intCountPrimaryFeatures = len(listObsPrimaryFeatures)\n",
    "\n",
    "# Print count \n",
    "print(f\"Count basis features: {intCountBasisFeatures}\")\n",
    "print(f\"Count primary features: {intCountPrimaryFeatures}\")\n",
    "print(f\"Count of total observed features: {dataRawGfdUs.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the correct amount of features for each category. The data dictionary is now created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictDataDescription = {}\n",
    "dictPrimaryDataDescription = {}\n",
    "dictBasisDataDescription = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in listObsPrimaryFeatures:\n",
    "    description = dataLabelDetailsGfd[dataLabelDetailsGfd['abr_jkp'] == feat]['name_new']\n",
    "    dictPrimaryDataDescription[feat] = {\n",
    "        \"Type\": dataRawGfdUs[feat].dtype,\n",
    "        \"Description\": description.values[0] if not description.empty else \"N/A\",\n",
    "        \"Pre-trans Range\": f\"[{dataRawGfdUs[feat].min()}, {dataRawGfdUs[feat].max()}]\" if pd.api.types.is_numeric_dtype(dataRawGfdUs[feat].dtype) else \"N/A\",\n",
    "        \"Pre-clean NaNs\": dataRawGfdUs[feat].isna().sum(),\n",
    "        \"Transformation\": \"None\",\n",
    "        \"Post-trans Range\": \"N/A\",\n",
    "        \"Post-clean NaNs\": \"N/A\",\n",
    "        \"Outlier handled (T/F)\": False\n",
    "    }\n",
    "\n",
    "for feat in listObsBasisFeatures:\n",
    "    description = dataLabelDetailsGfd[dataLabelDetailsGfd['abr_jkp'] == feat]['name_new']\n",
    "\n",
    "    dictBasisDataDescription[feat] = {\n",
    "        \"Type\": dataRawGfdUs[feat].dtype,\n",
    "        \"Description\": description.values[0] if not description.empty else \"N/A\",\n",
    "        \"Pre-trans Range\": f\"[{dataRawGfdUs[feat].min()}, {dataRawGfdUs[feat].max()}]\" if pd.api.types.is_numeric_dtype(dataRawGfdUs[feat].dtype) else \"N/A\",\n",
    "        \"Pre-clean NaNs\": dataRawGfdUs[feat].isna().sum(),\n",
    "        \"Transformation\": \"None\",\n",
    "        \"Post-trans Range\": \"N/A\",\n",
    "        \"Post-clean NaNs\": \"N/A\",\n",
    "        \"Outlier handled (T/F)\": False\n",
    "    }\n",
    "\n",
    "dictDataDescription = {\n",
    "    \"Basis\": dictBasisDataDescription,\n",
    "    \"Primary\": dictPrimaryDataDescription\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Type': Float64Dtype(),\n",
       " 'Description': 'Book-to-market enterprise value',\n",
       " 'Pre-trans Range': '[1.3169633700051e-17, 38265.70349130235]',\n",
       " 'Pre-clean NaNs': np.int64(955783),\n",
       " 'Transformation': 'None',\n",
       " 'Post-trans Range': 'N/A',\n",
       " 'Post-clean NaNs': 'N/A',\n",
       " 'Outlier handled (T/F)': False}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictDataDescription['Primary']['bev_mev']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bachelor_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

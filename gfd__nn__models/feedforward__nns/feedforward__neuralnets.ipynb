{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='font-family: CMU Sans Serif, sans-serif;'> Feed-Forward Neural-Networks  </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='font-family: CMU Sans Serif, sans-serif;'> Workflow  </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we look at different feed-forward achitectures. To find the *optimal models* within each achitectures we implement grid search with successive handling to stop poorly performing models early. We use a pythonian approach to building the models (*i.e. we create modules for each model*). For architecture we will define the following hyper-parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Hyper-parameter               | Variable                                                           |\n",
    "|-------------------------------|--------------------------------------------------------------------|\n",
    "| Number of epochs              | $E$                                                                |\n",
    "| Amount of hidden layers       | $R$                                                                |\n",
    "| Amount of neuron per layer    | $n^{(r)}$                                                          |\n",
    "| Learning rate                 | $\\alpha$                                                           |\n",
    "| Mini-batch size               | $m$                                                                |\n",
    "| $L_1$ or $L_2$ regularization | $L_1$ or $L_2$                                                     |\n",
    "| Regularization factor         | $\\lambda$                                                          |\n",
    "| Optimization algorithm        | $\\text{Adam}$, or $\\text{RMSprop}$, or $\\text{SGD}$ with momentum. |\n",
    "| Momentum in $\\text{SGD}$      | $\\mu$                                                              |\n",
    "| Activation function           | $\\text{ReLU}$, $\\text{PReLU}$, $\\text{Leaky ReLU}$                 |\n",
    "| Dropout (bool)                | $\\text{Dropout}^{T}$ or $\\text{Dropout}^{F}$                       |\n",
    "| Dropout parameter             | $p$                                                                |\n",
    "| Last hidden layer $\\tanh$     | $\\text{True}$ or $\\text{False}$                                    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='font-family: CMU Sans Serif, sans-serif;'> Package Import  </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data handling\n",
    "from typing import Union, List, Dict, Optional\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import uuid\n",
    "import os\n",
    "\n",
    "\n",
    "# Neural networks\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import keras.optimizers\n",
    "import keras.losses\n",
    "import keras.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='font-family: CMU Sans Serif, sans-serif;'> Data </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='font-family: CMU Sans Serif, sans-serif;'> Import  </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we import the main dataframe and the list of remaining primary features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import main data\n",
    "data_gfd_usa = pd.read_csv('../data__clean/usa__gfd__cleaned_v2.csv')\n",
    "\n",
    "# Import primary features remaining\n",
    "with open('../data__clean/listPrimaryFeaturesRemaining.json', 'r') as f:\n",
    "    list_primary_features = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='font-family: CMU Sans Serif, sans-serif;'> Train/Test Split  </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to split data into test and train for training and model validation. This is done below with the scikit-learn package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features and labels from data\n",
    "data_features = data_gfd_usa[list_primary_features]\n",
    "data_labels = data_gfd_usa['ret_exc_lead1m']\n",
    "\n",
    "# Split features and labels into test and train\n",
    "data_train_features, data_test_features, data_train_labels, data_test_labels = train_test_split(data_features, data_labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='font-family: CMU Sans Serif, sans-serif;'> Building Modules  </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is below: (1 custom classes that can be used on all models, and (2) specific classes for each architecture (or complexities within architectures)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='font-family: CMU Sans Serif, sans-serif;'> Functions and classes  </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='font-family: CMU Sans Serif, sans-serif;'> Get optimizer function  </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep things (*semi*) simple only 3 optimizers can be used: adam, SGD, RMSprop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(optimizer: str = \"adam\", **kwags):\n",
    "    dflt_vals = {\n",
    "        \"sgd\": {\"learning_rate\": 0.01, \"momentum\": 0.0},\n",
    "        \"adam\": {\n",
    "            \"learning_rate\": 0.01,\n",
    "            \"beta_1\": 0.9,\n",
    "            \"beta_2\": 0.999,\n",
    "            \"epsilon\": 1e-07,\n",
    "        },\n",
    "        \"rmsprop\": {\n",
    "            \"learning_rate\": 0.01,\n",
    "            \"rho\": 0.9,\n",
    "            \"momentum\": 0.0,\n",
    "            \"epsilon\": 1e-07,\n",
    "            \"centered\": False,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # Optimizer class for each optimizer\n",
    "    optimizer_classes = {\n",
    "        \"adam\": tf.keras.optimizers.Adam,\n",
    "        \"sgd\": tf.keras.optimizers.SGD,\n",
    "        \"rmsprop\": tf.keras.optimizers.RMSprop,\n",
    "    }\n",
    "\n",
    "    # Normalize optimizer name\n",
    "    optimizer_name = optimizer.lower()\n",
    "\n",
    "    # Check if optimizer is supported\n",
    "    if optimizer_name not in dflt_vals:\n",
    "        raise ValueError(f\"Optimizer '{optimizer_name}' not supported.\")\n",
    "\n",
    "    # Get default values for chosen optimizer\n",
    "    dflt = dflt_vals[optimizer_name]\n",
    "\n",
    "    # Get optimizer params (dict)\n",
    "    optimizer_params = {param: kwags.get(param, dflt[param]) for param in dflt}\n",
    "\n",
    "    # Get optimizer class\n",
    "    optimizer_class = optimizer_classes[optimizer_name]\n",
    "\n",
    "    # Return optimizer with given or default params\n",
    "    return optimizer_class(**optimizer_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='font-family: CMU Sans Serif, sans-serif;'> Callback function  </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks(earlystop=False, checkpoint=False, **kwargs):\n",
    "    callback_map = {\n",
    "        \"earlystop\": (\n",
    "            EarlyStopping,\n",
    "            {\n",
    "                \"monitor\": \"val_loss\",\n",
    "                \"min_delta\": 0,\n",
    "                \"patience\": 0,\n",
    "                \"verbose\": 0,\n",
    "                \"mode\": \"auto\",\n",
    "                \"baseline\": None,\n",
    "                \"restore_best_weights\": False,\n",
    "                \"start_from_epoch\": 0,\n",
    "            },\n",
    "        ),\n",
    "        \"checkpoint\": (\n",
    "            ModelCheckpoint,\n",
    "            {\n",
    "                \"filepath\": \"test\",\n",
    "                \"monitor\": \"val_loss\",\n",
    "                \"verbose\": 0,\n",
    "                \"save_best_only\": False,\n",
    "                \"save_weights_only\": False,\n",
    "                \"mode\": \"auto\",\n",
    "                \"save_freq\": \"epoch\",\n",
    "                \"initial_value_threshold\": None,\n",
    "            },\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    callbacks = []\n",
    "\n",
    "    all_params = {\n",
    "        \"earlystop\": None,\n",
    "        \"checkpoint\": None,\n",
    "    }\n",
    "\n",
    "    for callback_name in callback_map.keys():\n",
    "        if locals()[callback_name]:\n",
    "            constructor, defaults = callback_map[callback_name]\n",
    "\n",
    "            merged_params = {\n",
    "                **defaults,\n",
    "                **{k: v for k, v in kwargs.items() if k in defaults},\n",
    "            }\n",
    "            callbacks.append(constructor(**merged_params))\n",
    "            all_params[callback_name] = merged_params\n",
    "\n",
    "    return callbacks, all_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='font-family: CMU Sans Serif, sans-serif;'> Model manager class  </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "#   See this chat for additional ideas on model manager class https://chatgpt.com/c/67e5e6d4-c9b0-8004-98c4-375eb9e89c38\n",
    "\n",
    "\n",
    "class ModelManager:\n",
    "    # Class-level attribute to store the names of every model\n",
    "    _all_model_names = set()\n",
    "\n",
    "    @classmethod\n",
    "    def get_all_model_names(cls):\n",
    "        return list(cls._all_model_names)\n",
    "\n",
    "    @classmethod\n",
    "    def remove_model_name(cls, model_name):\n",
    "        cls._all_model_names.discard(model_name)\n",
    "\n",
    "    def __init__(self, model, optimizer, model_name):\n",
    "\n",
    "        self.model = model\n",
    "        self.model_name = model_name\n",
    "        self.optimizer = optimizer\n",
    "        self.callbacks = []\n",
    "        self.training_history = {}\n",
    "        ModelManager._all_model_names.add(model_name)\n",
    "\n",
    "    def compile_model(self, loss: str = \"mse\", metrics: list = [\"mse\"]):\n",
    "        self.model.compile(optimizer=self.optimizer, loss=loss, metrics=metrics)\n",
    "        print(f\"Model '{self.model_name}' compiled successfully.\")\n",
    "\n",
    "    def setup_callbacks(self, earlystop=False, checkpoint=False, **kwargs):\n",
    "        # Default parameter values for the callbacks\n",
    "        callback_map = {\n",
    "            \"earlystop\": (\n",
    "                EarlyStopping,\n",
    "                {\n",
    "                    \"monitor\": \"val_loss\",\n",
    "                    \"min_delta\": 0,\n",
    "                    \"patience\": 0,\n",
    "                    \"verbose\": 0,\n",
    "                    \"mode\": \"auto\",\n",
    "                    \"baseline\": None,\n",
    "                    \"restore_best_weights\": False,\n",
    "                    \"start_from_epoch\": 0,\n",
    "                },\n",
    "            ),\n",
    "            \"checkpoint\": (\n",
    "                ModelCheckpoint,\n",
    "                {\n",
    "                    \"filepath\": \"test\",  # Placeholder filepath\n",
    "                    \"monitor\": \"val_loss\",\n",
    "                    \"verbose\": 0,\n",
    "                    \"save_best_only\": False,\n",
    "                    \"save_weights_only\": False,\n",
    "                    \"mode\": \"auto\",\n",
    "                    \"save_freq\": \"epoch\",\n",
    "                    \"initial_value_threshold\": None,\n",
    "                },\n",
    "            ),\n",
    "        }\n",
    "\n",
    "        # Start with an empty list of callbacks\n",
    "        self.callbacks = []\n",
    "\n",
    "        # EarlyStopping Callback\n",
    "        if earlystop:\n",
    "            # Extract the class and default params from the callback_map\n",
    "            callback_class, default_params = callback_map[\"earlystop\"]\n",
    "            # Merge defaults with any kwargs passed by the user\n",
    "            merged_params = {\n",
    "                **default_params,\n",
    "                **{k: v for k, v in kwargs.items() if k in default_params},\n",
    "            }\n",
    "            earlystop_callback = callback_class(**merged_params)\n",
    "            self.callbacks.append(earlystop_callback)\n",
    "            print(f\"Configured early stop params: {merged_params}\")\n",
    "\n",
    "        # ModelCheckpoint Callback\n",
    "        if checkpoint:\n",
    "            # Extract the class and default params from the callback_map\n",
    "            callback_class, default_params = callback_map[\"checkpoint\"]\n",
    "            # Create the 'check_points' folder if it doesn't exist\n",
    "            checkpoint_dir = \"check_points\"\n",
    "            if not os.path.exists(checkpoint_dir):\n",
    "                os.makedirs(checkpoint_dir)\n",
    "\n",
    "            # Merge defaults with any kwargs passed by the user\n",
    "            merged_params = {\n",
    "                **default_params,\n",
    "                **{k: v for k, v in kwargs.items() if k in default_params},\n",
    "            }\n",
    "            # Use the model_name for the checkpoint file path\n",
    "            merged_params[\"filepath\"] = os.path.join(\n",
    "                checkpoint_dir, f\"{self.model_name}_check_points.keras\"\n",
    "            )\n",
    "            checkpoint_callback = callback_class(**merged_params)\n",
    "            self.callbacks.append(checkpoint_callback)\n",
    "            print(f\"Configured checkpoint params: {merged_params}\")\n",
    "\n",
    "        print(f\"Callbacks for model '{self.model_name}' have been set up.\")\n",
    "\n",
    "    def train_model(\n",
    "        self,\n",
    "        x,\n",
    "        y,\n",
    "        epochs=10,\n",
    "        batch_size=32,\n",
    "        verbose=1,\n",
    "        validation_split=0.2,\n",
    "    ):\n",
    "        self.model.fit(\n",
    "            x,\n",
    "            y,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            verbose=verbose,\n",
    "            callbacks=self.callbacks,\n",
    "            validation_split=validation_split,\n",
    "        )\n",
    "        print(f\"Model '{self.model_name}' trained succesfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='font-family: CMU Sans Serif, sans-serif;'> Building networks  </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='font-family: CMU Sans Serif, sans-serif;'> Vanilla FFN  </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='font-family: CMU Sans Serif, sans-serif;'> Vanilla FNN function  </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we define a function for building vanilla feed forward neural networks.\n",
    "\n",
    "We allow for varying the following parameters dynamically:\n",
    "- number of neurons in each layer;\n",
    "- type of activation function used in each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vanilla_fnn(\n",
    "    input_shape = (141,),\n",
    "    layer_neurons  = [32, 16, 1],\n",
    "    activations = [\"relu\", \"tanh\", None]\n",
    "):\n",
    "    # Same length of inputs\n",
    "    assert len(layer_neurons) == len(\n",
    "        activations\n",
    "    ), \"layer_neurons and activations must have same length.\"\n",
    "    model_id = str(uuid.uuid4())\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.Input(shape=input_shape))\n",
    "\n",
    "    for i, (units, activation) in enumerate(zip(layer_neurons[:-1], activations[:-1])):\n",
    "        model.add(\n",
    "            tf.keras.layers.Dense(\n",
    "                units, activation=activation, name=f\"{model_id}_dense_{i+1}\"\n",
    "            )\n",
    "        )\n",
    "    model.add(\n",
    "        tf.keras.layers.Dense(\n",
    "            layer_neurons[-1],\n",
    "            activation=activations[-1],\n",
    "            name=f\"{model_id}_dense_{len(layer_neurons)}\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='font-family: CMU Sans Serif, sans-serif;'> Creating a NN  </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lest try our creating a first neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351524, 141)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_optimizer = get_optimizer('adam')\n",
    "simple_fnn = build_vanilla_fnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnn_mm = ModelManager(model = simple_fnn, optimizer = simple_optimizer, model_name = \"first_vanilla_fnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 'first_vanilla_fnn' compiled successfully.\n"
     ]
    }
   ],
   "source": [
    "fnn_mm.compile_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configured early stop params: {'monitor': 'val_loss', 'min_delta': 0, 'patience': 0, 'verbose': 0, 'mode': 'auto', 'baseline': None, 'restore_best_weights': False, 'start_from_epoch': 0}\n",
      "Callbacks for model 'first_vanilla_fnn' have been set up.\n"
     ]
    }
   ],
   "source": [
    "fnn_mm.setup_callbacks(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.src.callbacks.early_stopping.EarlyStopping at 0x177b2d0d0>]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnn_mm.callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m8789/8789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 432us/step - loss: 0.0267 - mse: 0.0267 - val_loss: 0.0267 - val_mse: 0.0267\n",
      "Epoch 2/10\n",
      "\u001b[1m8789/8789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 426us/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 3/10\n",
      "\u001b[1m8789/8789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 430us/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Model 'first_vanilla_fnn' trained succesfully.\n"
     ]
    }
   ],
   "source": [
    "fnn_mm.train_model(data_train_features, data_train_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bachelor_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
